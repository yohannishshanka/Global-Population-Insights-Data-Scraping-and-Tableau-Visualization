{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73da41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yohan\\AppData\\Local\\Temp\\ipykernel_9464\\3187880946.py:13: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to C:/Users/Yohan/Documents/mindam/population/population.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# URL containing the tables\n",
    "url = 'https://www.worldometers.info/world-population/population-by-country/'\n",
    "\n",
    "# Path to your ChromeDriver executable\n",
    "chrome_driver_path = 'C:/Users/Yohan/Documents/mindam/population/chromedriver.exe'\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get(url)\n",
    "\n",
    "# Allow time for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Get the page source and parse it with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Find all tables on the page\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Create an ExcelWriter object to save multiple sheets\n",
    "excel_file_path = 'C:/Users/Yohan/Documents/mindam/population/population.xlsx'\n",
    "with pd.ExcelWriter(excel_file_path, engine='xlsxwriter') as writer:\n",
    "    # Iterate over each table and extract data\n",
    "    for index, table in enumerate(tables):\n",
    "        # Extract all rows from the table\n",
    "        rows = table.find_all('tr')\n",
    "\n",
    "        # Extract the headers\n",
    "        headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
    "\n",
    "        # Extract the table data\n",
    "        data = []\n",
    "        for row in rows[1:]:\n",
    "            cells = row.find_all('td')\n",
    "            data.append([cell.text.strip() for cell in cells])\n",
    "\n",
    "        # Create a DataFrame from the data\n",
    "        df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "        # Save the DataFrame to an Excel sheet\n",
    "        sheet_name = f'Table_{index + 1}'\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Data has been saved to {excel_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ed08a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yohan\\AppData\\Local\\Temp\\ipykernel_9464\\1355889070.py:13: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World_Population_(2024_and_historical) saved as 'World_Population_(2024_and_historical)'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# URL containing the tables\n",
    "url = 'https://www.worldometers.info/world-population/'\n",
    "\n",
    "# Path to your ChromeDriver executable\n",
    "chrome_driver_path = 'C:/Users/Yohan/Documents/mindam/population/chromedriver.exe'\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get(url)\n",
    "\n",
    "# Allow time for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Get the page source and parse it with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Find all tables on the page\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Extract all rows from the 5th table\n",
    "rows = tables[3].find_all('tr')\n",
    "\n",
    "# Extract the headers\n",
    "headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
    "\n",
    "# Extract the table data\n",
    "data = []\n",
    "for row in rows[1:]:\n",
    "    cells = row.find_all('td')\n",
    "    data.append([cell.text.strip() for cell in cells])\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('World_Population_(2024_and_historical).xlsx', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"World_Population_(2024_and_historical) saved as 'World_Population_(2024_and_historical)'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc6be041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yohan\\AppData\\Local\\Temp\\ipykernel_9464\\2462220913.py:13: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World_Population_Forecast_(2025-2050) saved as 'World_Population_Forecast_(2025-2050).xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# URL containing the tables\n",
    "url = 'https://www.worldometers.info/world-population/'\n",
    "\n",
    "# Path to your ChromeDriver executable\n",
    "chrome_driver_path = 'C:/Users/Yohan/Documents/mindam/population/chromedriver.exe'\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get(url)\n",
    "\n",
    "# Allow time for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Get the page source and parse it with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Find all tables on the page\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Extract all rows from the 5th table\n",
    "rows = tables[4].find_all('tr')\n",
    "\n",
    "# Extract the headers\n",
    "headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
    "\n",
    "# Extract the table data\n",
    "data = []\n",
    "for row in rows[1:]:\n",
    "    cells = row.find_all('td')\n",
    "    data.append([cell.text.strip() for cell in cells])\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('World_Population_Forecast_(2025-2050).xlsx', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"World_Population_Forecast_(2025-2050) saved as 'World_Population_Forecast_(2025-2050).xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e2f642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yohan\\AppData\\Local\\Temp\\ipykernel_9464\\3688996015.py:13: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World_Population_by_Region saved as 'World_Population_by_Region.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# URL containing the tables\n",
    "url = 'https://www.worldometers.info/world-population/'\n",
    "\n",
    "# Path to your ChromeDriver executable\n",
    "chrome_driver_path = 'C:/Users/Yohan/Documents/mindam/population/chromedriver.exe'\n",
    "\n",
    "# Initialize the WebDriver\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "driver.get(url)\n",
    "\n",
    "# Allow time for the page to load\n",
    "time.sleep(5)\n",
    "\n",
    "# Get the page source and parse it with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Find all tables on the page\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "\n",
    "# Ensure that there are at least 6 tables\n",
    "if len(tables) < 6:\n",
    "    raise ValueError(\"The page does not contain 6 tables as expected.\")\n",
    "\n",
    "# Extract all rows from the 6th table (index 5)\n",
    "rows = tables[6].find_all('tr')\n",
    "\n",
    "# Extract the headers\n",
    "headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
    "\n",
    "\n",
    "\n",
    "# Extract the table data\n",
    "data = []\n",
    "for row in rows[1:]:\n",
    "    cells = row.find_all('td')\n",
    "    data.append([cell.text.strip() for cell in cells])\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "if headers:\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "else:\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel('World_Population_by_Region.xlsx', index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"World_Population_by_Region saved as 'World_Population_by_Region.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6c359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
